^title Data Locality
^section Низкоуровневая оптимизация

## Общая мысль

*Если расположить данные в памяти специальным образом, то это поможет кэшам процессора.*

## Предыстория

Нас обманули. Нам показывают графики, на которых скорость процессоров растёт все выше и выше, как будто закон Мура - это не просто историческое наблюдение, а какое-то непререкаемое правило. Не отрывая задниц от кресла, мы, программисты, наблюдаем, как наши программы волшебным образом ускоряются благодаря апгрейду.

Процессоры *ускорялись* (сейчас график больше похож на плато), но главные по железу забыли нам кое-что сказать. Конечно, мы можем *обработать* данные быстрее чем раньше, но мы не можем *получить* их быстрее.

<span name="legend"></span>

<img src="images/data-locality-chart.png" />

<aside name="legend">

Скорость процессора и доступа к памяти относительно уровня 1980-го года. Как видно, скорость процессоров растет как на дрожжах, а вот доступ к памяти плетётся далеко позади.

Данные взяты из "Computer Architecture: A Quantitative Approach" John L. Hennessy, David A. Patterson, Andrea C. Arpaci-Dusseau by way of Tony Albrecht's "[Pitfalls of Object-Oriented Programming](http://research.scee.net/files/presentations/gcapaustralia09/Pitfalls_of_Object_Oriented_Programming_GCAP_09.pdf)".

</aside>

Для того, чтобы сверхбыстрый процессор провернул свои вычисления, ему, вообще-то, нужно выгрузить данные из главной памяти в свои регистры. И как видите, память не так быстра, как скорость процессора. Даже близко не так.

С современным уровнем развития железа, может понадобиться *сотни* тактов, чтобы вытащить байт из <span name="ram">RAM</span>. Если большинство операций связано с данными, и нужно сотни тактов, чтобы их получить - как так получается, что наши процессоры не бездельничают 99% времени, ожидая поступления данных?

На самом деле, они *действительно* ждут памать удивительно большую часть своего времени, но все не так плохо, как это могло бы быть. Чтобы объяснить почему, давайте совершим сделаем длинное лирическое отступление...

<aside name="ram">

Она называется RAM ("Random access memory") потому что можно получить доступ к любому участку памяти одинаково быстро (это в теории). То есть не нужно считывать все байты по очереди, чтоб добраться до нужного места.

Ну, *обычно* не нужно. Как будет видно дальше, RAM не всегда настолько гибка, как кажется.

</aside>

### Хранилище данных

Представьте, что вы -- бухгалтер в маленьком офисе. Ваша работа: получить коробку документов и сделать с ними что-нибудь <span name="accountant">бухгалтерское</span>. Например, сложить какие-то числа. Это нужно сделать только с документами из некоторых коробок, в соответствии с какими-то тайными правилами, которые понятны только другим бухгалтерам.

<aside name="accountant">

Наверное, не стоило здесь использовать бухгалтерию -- я ничего в ней не понимаю.

</aside>

Благодаря тяжелой работе, природной упорности и стимуляторам, можно обработать всю коробку, скажем, за минуту. Но есть одна проблема - все эти коробки хранятся на складе в отдельном здании. Чтобы получить коробку, вам нужно попросить парня со склада принести её вам. Он идет, берет подъемник и ездит вдоль стеллажей, пока не найдет коробку, которая вам нужна.

Все это займет целый день, без шуток. В отличие от вас, парень со склада ещё не скоро станет работников месяца. Это значит, что неважно насколько вы быстры -- вы все рано получите не больше одной коробки в день. Все остальное время вы будете просто сидеть и думать о жизни, которая привела вас к такой бессмысленной работе.

И вот однажды, появилась группа специалистов. Их работа -- увеличивать эффективность работы. Придумывать маленькие хаки, которые позволяют сборочной линии двигаться быстрее. Они понаблюдали за вами несколько дней, и сделали несколько замечаний:

* Довольно часто, следущая коробка, которую вы попросите, находится <span name="next">на одной полке</span> с предыдущей.

* Использовать подъемник, чтобы снять маленькую коробку с полки -- довольно неэффективная идея.

* И в вашем офисе есть немного места в углу.

<aside name="next">

Эта ситуация (когда вы используете вещь, которая лежала рядом с той, которую вы только что использовали) в техническом мире называется *компактность ссылок*.

</aside>

Это дельный совет. Теперь, когда вы запрашиваете коробку у парня со склада, он приносит вам целую палету. Не только коробку, которая вам нужна, но и несколько соседних тоже. Он не знает, понадобятся ли они вам (вообще говоря, ему просто по барабану) -- он просто берет столько коробок, сколько может унести.

Итак, он загружает целую палету и несет её вам. Игнорируя правила безопасности, он въезжает на подъемнике прямо к вам в офис и сгружает все это прямо у вас в углу.

Когда вам нужна будет новая коробка, вы первым делом смотрите в углу -- возможно следущая коробка уже там. Если она действительно там, то вам повезло! Вам нужна всего секунда, чтобы взять новую коробку и занятся магией чисел. Если в куче 50 коробок, и вам так повезло, что *все* следующие коробки находятся в куче, то вы можете сделать в 50 раз больше работы чем раньше.

Но, если коробка, которая вам нужна, в куче *отсутствует*, вам все-таки придется её заказать. Поскольку в угол влезает только одна палета, то парень со склада приедет, заберет старую кучу и затем привезет вам совершенно новую кучу.

### Куча для процессора

Может показаться странным, но в современных компьютерах процессоры работают точно также. Офисный стол бухгалтера - это регистры процессора, а коробка с документами -- данные, которые можно положить в регистры. Склад -- это RAM вашего компьютера, а тот надоедливый парень со склада -- шина, которая наполняет регистры данными из памяти.

Если бы эта книга писалась тридцать лет назад, здесь история бы и закончилась. Но так как процессоры становятся быстрее, а RAM, грубо говоря, *нет*, инженеры начали искать решение. И они пришли к тому, что называется *кэшем процессора*.

В современных компьютеры если  <span name="caches">маленький объем</span> памяти прямо внутри процессора. Он может достать оттуда данные быстрее, чем из основной памяти. Этот объем достаточно мал, чтобы уместиться в процессоре, и довольно дорог, потому что используется особый, быстрый тип памяти (static RAM или "SRAM").

<aside name="caches">

Вообще, кэшей несколько. В зависимости от уровня они называются по-разному -- "L1", "L2", "L3" и так далее. Каждый уровень больше и медленнее предыдущего. В этой главе мы не будем углубляться в детали [иерархии памяти](http://ru.wikipedia.org/wiki/Иерархия_памяти), но это полезно знать.

</aside>

Этот маленький кусочек памяти называется *кэшем* (в частности, этот можно назвать *кэш L1*), и в нашей истории он эквивалентен куче коробок. Как только процессору понадобится байт памяти из RAM, он автоматически забирает целый кусок непрерывных данных -- обычно от 64 до 128 байт -- и кладет их в кэш. Эта порция памяти называется *кэш-линией*.

<img src="images/data-locality-cache-line.png" />

Если <span name="pallet">следующий байт</span> данных, который вам нужен, случайно окажется к этой линии, процессор прочитает его прямо из кэша, что *гораздо* быстрее чем обращение к RAM. Эту ситуацию, когда данные в кеше, называют *попаданием в кэш*. Если данных нет в кеше и приходится запрашивать главную память -- это *кэш-промах*.

<aside name="pallet">

Я приукрасил одну (по крайней мере) деталь в нашей истории. В офисе можно положить только одну кучу, то есть одну кэш-линию. Кэш процессора содержит несколько кэш-линий. Вы сможете утолить свое любопытство, поискав по слову "ассоциативность кэша".

</aside>

Когда случается кэш-промах, процессор *замирает*: он не может выполнить инструкцию, потому что ему нужны данные. Он просто стоит и скучает следующие несколько сотен тактов пока данные не появятся. Наша задача -- избежать этого. Допустим, мы хотит увеличить производительность важной части кода, который выглядит вот так:

^code do-nothing

Какой бы был ваш первый шаг? Правильно! Уберем этот бессмысленный и дорогой вызов функции. Вызов функции по стоимости эквивалентен кэш-промаху. Каждый раз вы выскакиваете в основную память -- это как вставить задержку в код.

### Разве данные -- это производительность?

Когда я начал работать над этой главой, я потратил время на примеры , которые показали бы хороший и плохой вариант использования кэша. Мне нужны были тесты, которые гоняли бы кэш, чтобы непосредственно увидеть все эффекты.

И когда я сделал часть работы, я был удивлен. Я знал, что кэш важен, но увидеть это своими глазами -- это нечто. <span name="ymmv">Я написал две программы</span>, которые делали *совершенно одинаковые* вещи. Единственное отличие было в том, как много кэш-промахов они получали. И худший вариант был в 50 *раз* медленнее, чем лучший.

<aside name="ymmv">

Здесь есть тонкости. В частности, разные компьютеры имеют разный кэш, поэтому мой комьютер может отличаться от вашего. А игровые консоли совсем отличны от дескторов, которые имеют много разного с мобильными устройствами.

Ваши результаты могут отличаться.

</aside>

Это по-настоящему открыло мне глаза. Я думал, на быстродействие влияет *код*, а не *данные*. Байт не бывает быстрым или медленным, он просто есть. Но из-за кэширования, *способ управления памятью прямо влияет на производительность*.

Теперь нужно все это применить к нашей теме. Оптимизация использования кэша -- довольно объемная тема. Я даже не упомянул о *кэшировании инструкций*. Вспомните -- код находится в памяти тоже, и его тоже нужно загрузить в процессор перед тем как выполнить. Кто-то более осведомленный может написать целую <span name="book">книгу</span> об этом.

<aside name="book">

На самом деле, кто-то *уже* написал книгу об этом:  [*Data-Oriented Design*](http://www.dataorienteddesign.com/dodmain/) от Ричарда Фабиана.

</aside>

Так как вы всё-таки читаете *эту* книгу, то я опишу несколько базовых вещей. Вместе с ними уже можно начать думать о том, как структуры данных влияют на производительность.

Все довольно просто: когда процессор считывать данные из памяти, он требует целую кэш-линию. Чем больше данных удасться <span name="line">положить в эту линию, тем быстрее все выполнится</span>. Так что надо *организовать ваши структуры так, чтобы вычисления оперировали с близко расположенными в памяти данными*.

<aside name="line">

Здесь есть ключевой момент:  контекст одного потока. Если вы модифицируете данные, используя несколько потоков, то лучше им находится в разных *кэш-линиях*. Если два потока попытаются изменить данные в одной и той же кэш-линии, обоим процессорам использовать синхронизацию кэшей, что довольно дорого.

</aside>

Другими словами, если ваш код использует `одно`, затем `другое`, потом `третье`, вам лучше расположить это в памяти как-то так:

<img src="images/data-locality-things.png" />

Заметьте, это не *указатели* на `одно`, `другое` и `третье`. Это настоящие данные, расположенные в одну линию. Как только процессор потребует `одно`, он сразу же получит и `другое`, и `третье` (вообще это зависит от того, насколько эти штуки большие, и от размера кэш-линии). Когда начнуться вычисления, данные уже будут в кэше. Ваш процессор счастлив, значит -- и вы счастливы.

## Общий подход

Современные **процессоры имеют кэш для ускорения доступа к памяти**. Доступ к соседним участкам памяти **осуществляется намного быстрее**. Этим можно воспользоваться **увеличивая компактность данных** -- хранить данные **непрерывно, в соответствии с порядком их обработки**.

## Когда этим пользоваться

Как и при большинстве оптимизаций, первым делом нужно убедится что *есть проблема с быстродействием*. Не тратьте время, пытаясь ускорить редко используемый участок кода. Преждевременная оптимизация усложнит вашу жизнь, так как результат почти всегда сложен и менее гибок.

Применительно к нашей теме, нужно убедиться, что быстродействие *действительно страдает от кэш-промахов*. Если код медленный по другим причинам, то лекарство не поможет.

В простом случае выследить проблему поможет инструментация. Она измерит время выполнения кода между двумя точками с использованием точного таймера. Для отлова кэш-промахов понадобиться что-то посложнее. Нужно увидеть, как много случилось промахов, и в каком месте.

К счастью, есть <span name="cachegrind">профайлеры</span>, которые могут помочь. Придется потратить время на настройку такого профайлера и научится воспринимать его (часто непростые) отчеты, перед тем как приступить к главному действу по оптимизации структур с данными.

<aside name="cachegrind">

К сожалению, такие профайлеры недешевы. Если вы в команде, которая работает с консолями, у вас скорее всего уже есть какая-нибудь лицензия.

Если нет, то если бесплатный [cachegrind](http://valgrind.org/docs/manual/cg-manual.html). Он выполняет программу в эмуляторе процессора и показывает все операции с кэшем.

</aside>

Как уже говорилось, кэш-промахи *повлияют* на быстродействие вашей игры. И все же не увлекайтесь тратой времени на преждевременную оптимизацию кэша. Просто помните при разработке архитектуры -- организовать структуры стоит так, чтобы они хорошо работали в кэше.

## Особенности

Отличительный признак архитектуры программы -- *абстрация*. Большая часть это книги рассказывает о том, как отвязать куски кода друг от друга так, чтобы они были легко изменяемы. В языках ООП это почти всегда означает интерфейсы.

В C++ использование интерфейсов предполагает доступ к объектам через <span name="virtual">указатели или ссылки</span>. Доступ через указатель означает прыжки в памяти, которые ведут к кэш-промахам -- а мы стараемся их избежать.

<aside name="virtual">

Другая особенность интерфейсов -- *виртуальные методы*. Для того чтобы вызвать такой метод, необходимо получить доступ к виртуальной таблице объекта и найти там указатель на функцию, которую необходимо вызвать. То есть, игра в указатели опять приводит к кэш-промахам.

</aside>

Для того, чтобы воспользоваться оптимизацией, придется пожертвовать частью абстракций. Чем больше вы концентрируете архитектуру программы вокруг компактности данных, тем меньше применения находится наследованию и интерфейсам -- и всем их сильным сторонам. Серебрянной пули здесь нет, угодить всем не удасться. Тем веселее!

## Примеры

Если заняться оптимизацией локальности данных, то можно придумать бесконечно много способов разложения ваши структур на кусочки, с которыми процессору будет удобно работать. Для общего понимания я покажу примеры основных реализаций этих идей. Мы рассмотрим их в контексте части игрового кода, но это общая техника, поэтому применить её возможно везде (как и все остальные паттерны).

### Непрерывные массивы

Начнем мы с <a href="game-loop.html" class="pattern">Game Loop</a>, который обрабатывает набор внутренних объектов. Эти объекты разделены на несколько областей -- AI, физика и рендеринг -- с использованием паттерна <a href="component.html" class="pattern">Component</a>. Вот класс объекта:

 ^code game-entity

Каждый компонент имеет относительный малый набор аттрибутов (не больше пары векторов или одной матрицы) и метод <span name="update">update</span>, который их обновляет. Детали не так важны здесь, просто представьте что-то вроде следующего:

<aside name="update">

Метод update -- это пример паттерна <a href="update-method.html" class="pattern">Update Method</a>.  Как и `render()`, просто с другим именем.

</aside>

^code components

Игра оперирует с большим массивом указателей на эти объекты. В каждой игровой итерации происходит следующее:

1. Обновляем AI для всех объектов.

2. Применяем к ним физику.

3. И отображаем все объекты с помощью рендера.

Большинство игр прямо так и делают:

^code game-loop

До того как вы узнали про кэш процессора, все выглядело абсолютно невинно. Но сейчас у вас возникло подозрение, что то-то делается неправильно. Код не использует кэш по полной, вместо этого он просто убивает его. Смотрите, что происходит:

1. Массив объектов -- это *указатели* на объекты. Когда мы образаемся к объекту, мы достаем данные по указателю. Это кэш-промах.

2. Затем мы достаем компонент из указателя в объекте. Ещё кэш-промах.

3. Затем мы вызываем метод компонента.

4. И возвращаемся к шагу 1, чтобы повторить его для *каждого компонента каждого игрового объекта*.

The scary part is we have no idea how these objects are laid out in memory.
We're completely at the mercy of the memory manager. As entities get allocated
and freed over time, the heap is likely to become increasingly randomly
organized.

<span name="lines"></span>

<img src="images/data-locality-pointer-chasing.png" />

<aside name="lines">

Движку приходится бегать по этим стрелками каждый игровой ход, чтобы достать данные.

</aside>

Это было бы здорово, если бы мы хотели "объехать всю память за 80 дней"! Но нам нужно сделать цикл быстро и <span name="chase">бродить</span> по всей памяти не наш метод. Помните функцию `sleepFor500Cycles()`? Ну так вот -- этот код использует её *постоянно*.

<aside name="chase">

Трата времени на разыменование указателей называется "блуждание по указателям", и это не так весело как кажется.

</aside>

Придумаем что-нибудь получше. С первого взгляда ясно, что указатель на объект нам нужен только для доступа к *другому* указателю на его компонент. Сам `GameEntity`нам не интересен и дает нам ничего полезного. *Компоненты* -- вот что нужно циклу.

Срубим под корень раскидистое дерево указателей на объекты! Нам нужно оформить по массиву на каждый тип компонента: один плоский массив для AI, один для физики и ещё один для рендера.

Как-то так:

<span name="long-name"></span>

^code component-arrays

<aside name="long-name">

Меньше всего в компонентах мне нравится длина самого слова "компонент".

</aside>

Подчеркну, что это массив *компонентов*, а не *указателей на компонент*. Все данные прямо здесь, один за другим. Игровой цикл может оперировать прямо с ними:

<span name="arrow"></span>

^code game-loop-arrays

<aside name="arrow">

Показатель того, что мы движемся в правильном направлении, это уменьшение количества "`->`" в коде. Если вам нужно улучшить компактность данных, ищите эти операторы и избавляйтесь от них.

</aside>

Итак, мы выбросили блуждание по указателям. Вместо метания по памяти, мы перебираем три непрерывных массива с прямыми данными.

<img src="images/data-locality-component-arrays.png" />

Теперь плотный поток байтов загружается прямо в жадное горло процессора. По результатам тестов, это изменение ускоряет цикл в тридцать раз по сравнению с предыдущим вариантом.

Интересно, что мы почти не потеряли в инкапсуляции. Конечно, игровой цикл оперирует с компонентами напрямую, не доставая их из объектов. Но мы можем достать их заранее, чтобы убедиться что мы все делаем правильно. Более того, каждый компонент все ещё надежно инкапсулирован. Мы просто изменили способ доступа к ним.

Это не значит, что `GameEntity` больше не нужен. Мы оставим его, так как он все ещё держит указатели на свои компоненты. Они просто будут указывать на элементы наших массивов. Сам концепт "игрового объекта" может пригодиться в других частях кода. Важно, что для производительности игровой цикл обходит этот момент и использует данные напрямую.

### Упаковка

Допустим, мы делаем систему частиц. Следуя совету из предыдущей секции, мы загрузили все частици в один большой непрерывный массив. Придумаем маленькую <span name="pool">систему частиц</span>:

<aside name="pool">

Класс `ParticleSystem` является примером паттерна <a href="object-pool.html" class="pattern">Object Pool</a> для одного типа объекта.

</aside>

^code particle-system

Его метод <code>update</code> выглядит следующим образом:

^code update-particle-system

Но реальность показала, что нам не нужно обрабатывать *все* частицы каждый раз. Система содержит фиксированный набор частиц, но не все они активны на экране:

^code particles-is-active

Мы дали `Particle` флажок, по которому определяем активна она или нет. В цикле мы <span name="branch">проверяем</span> его для каждой частицы. Флажок загружается в кэш вместе с целым объектом. И если частица *не активна*, мы просто переходим к следующей. Остальные аттрибуты частицы бесполезно загружаются в кэш.

Чем меньше активных частиц, тем больше частиц загружается в кэш вхолостую. Если массив большой и *большинство* частиц неактивно, то мы просто насилуем кэш без пользы.

Идея хранения объектов в непрерывном массиве не сильно помогает, так как набор частиц, с которым мы реально будем работать, не непрерывен. Массив замусорен неактивными частицами, которые нам надо пропускать, и мы возвращаемся к первоначальной проблеме.

<aside name="branch">

Смышленные программисты увидят здесь и другую проблему. Выполнение условия `if` для каждой частицы может привести к *сбою предсказания переходов* и *простою конвейера*.  В процессорах одна "инструкция" может занять несколько тактов. Чтобы процессор не простаивал, инструкции *распараллеливают*, чтобы следующая инструкция начала обрабатываться, не дожидаясь конца предыдущей.

Процессор пытается угадать, какая инструкция выполнится следующей. В линейном коде это просто, но условные переходы усложняют жизнь. Пока выполняется условие для `if`, какую часть кода брать следующей --  `update()` или ничего не делать?

 Для ответа на этот вопрос процессор использует *предсказание переходов*: он видит, по какому пути пошел в прошлый раз и предполагает, что пойдет по нему опять. И когда флажок постоянно переключается, это предсказание терпит сбой.

Когда происходит сбой, процессор выкидывает инструкции, которые он уже начал выполнять (*сброс конвейера*) и начинает заново. Влияние этого на производительность зависит от характеристик машины, но это та причина, по которой некоторые программисты пытаются избежать ветвлений в критических местах.

</aside>

Из названия секции, вы можете догадаться о решении этого вопроса. Вместо проверки *флага*, мы отсортируем по нему. Поместим все активные частицы в начало списка. Если мы будем знать, что эти частицы активны, проверка флага нам просто не нужна.

Мы можем хранить количество активных частиц. Тогда код превратится в следующую прекрасную штуку:

^code update-particles

Теперь мы не пропускаем *ни одного* лишнего байта. Каждый загружается в кэш для реальной работы с частицей.

Конечно, я не говорю, что вам нужно использовать быструю сортировку (quicksort) всего массива каждый раз. Это уничтожит все наши победы. Нам просто нужно *поддерживать* сортировку.

Предположим, что массив уже отсортирован -- и это действительно для случая, когда все частицы неактивны. Сортировка *теряется*, когда частица переходит из неактивного состояния в активное и обратно. Это легко можно отследить. Как только частица становится активной, мы передвинем её на место первой *неактивной* частицы:

^code activate-particle

При деактивации частицы, сделаем обратный ход:

^code deactivate-particle

Большинство (включая меня) выработали аллергию на копирование памяти. Перекидывание кучи байтов *выглядит* тяжелой операцией по сравнению с перемещением указателя. Но если вы прибавите к этому *разыменование* этого указателя, выяснится, что интуиция иногда обманывает. В <span name="profile">некоторых случаях</span>, дешевле перекинуть данные в памяти, если это поможет операциям с кэшем.

<aside name="profile">

Это тонкий намек на пользу *профайлера* при принятии решений подобного рода.

</aside>

Есть очевидное преимущество от хранения частиц *отсортированными* по активности: теперь не нужен флаг. Он заменяется позицией частицы в массиве и счетчиком `numActive_`. Из-за этого класс частицы становиться чуточку меньше, значит их больше поместится в кэш-линию, и все завертится ещё быстрее.

Ести и минусы, конечно. Мы потеряли немного объектно-ориентированности здесь. Класс `Particle` больше не управляет своим состоянием активности. Вы не сможете сделать у частицы метод `activate()`, так как она просто не знает свой индекс. Вместо этого придется иметь доступ к *системе частиц*.

В данном случае, я считаю нормальным, что `ParticleSystem` и `Particle` так жестко связаны между собой. Решая нашу главную задачу, пришлось вылезти за границы одного класса. Ничего страшного -- скорее всего, именно система будет решать когда создавать частицы и когда их убивать.

### Hot/cold splitting

Это последний пример простой техники, которая может улучшить работу с кэшем. Допустим, у нас есть AI компонент для какого-то объекта. И он имеет какое-то состояние: анимация, которая сейчас запущена, точка, к которой он двигается, уровень энерги, и так далее -- все это проверяется и меняется каждый цикл игры. В общем, что-то вида:

^code ai-component

Но кроме этого есть ещё редкие события. Например, какие шмотки выпадут, если придется неудачно встретиться с шотганом лицом к лицу. Этот дроп используется только один раз, чаще всего в самом конце.

^code loot-drop

Если все паттерны, которые мы рассмотрели ранее, уже были применены, то при работе со всеми AI компонентами, мы будем работать с упакованным, непрерывным массивом данных. В этом массив будет включена и информацию о дропе. И как мы уже знаем, чем толще объект, тем меньше их будет загружаться в кэш-линию. Будет больше кэш-промахов, потому что память пухнет от данных, которые мы не используем.

То, что мы будем делать, называется "разделение на горячее и холодное". Идея в том, чтобы разбить структуру на два отдельных куска. Первый кусок содержит "горячие" данные: аттрибуты, которые нам нужны каждый раз. Другой кусок -- "холодные" данные: все, что используется более или менее редко.

Горячая часть -- это *сам* AI компонент. Он нам нужен каждый раз, поэтому указатель из него мы делать не будем, чтобы лишний раз по нему не бегать. А за холодными аттрибутами можно сбегать, поэтому мы будем получать их через указатель. Вот так:

^code hot-cold

Теперь, когда мы проходим по всем AI в цикле, в кэш будут загружаться только данные, который мы чаще всего используем (за <span name="parallel">исключением</span> одного маленького указателя на холодные аттрибуты).

<aside name="parallel">

В принципе, мы можем избавиться и от указателя тоже, если взять два параллельных массива с холодными и горячими аттрибутами. Используя один индекс, можно получить данные и из одного, и из другого массива.

</aside>

Заметьте, все это становится слегка запутанным. В данном примере, все очевидно: какие данные горячие, какие -- холодные. Но так бывает не всегда. Что, если у вас есть аттрибуты, которые используются часто в одном режиме игры, и редко -- в другом? Или, если у объекта есть аттрибуты, которые проявляются только на каком-нибудь уровне?

Подобная оптимизация похожа на игру в угадайку. Очень легко втянуться и бесконечно перекидывать данные из одного места в другое, выясняя, какая комбинация даст лучший эффект. Практикуйтесь, и научитесь понимать, где нужно применить свои знания в первую очередь.

## Архитектурные решения

Помните: ключевой момент в оптимизации -- это думать о том, как устроены ваши данные. Пространство решений велико. Техники <span name="dod">компактности данных</span> могут повлиять на всю архитектуру кода, или просто на какие-то критические куски.

Главный вопрос, на который вы будете искать ответ -- это где и когда применить свои знания. Но по пути встретятся и другие моменты.

<aside name="dod">

В [известной статье](http://gamesfromwithin.com/data-oriented-design) Ноэля Лописа (с которой знакомятся люди, учитывающие работу с кэшем при разработке игр) это называется "дизайн, ориентрированный на данные" (data-oriented design).

</aside>

### Как дела с полиморфизмом?

До этого момента, мы избегали наследования и виртуальных методов. Мы предполагали, что имеем массивы *однородных* данных. Таким образом, мы были уверены, что они все -- одинакового размера. Но полиморфизм и виртуальность -- весьма полезные штуки. Как подружить эти противоположности?

 *  **Просто не используйте:**

    <span name="type">Очевидным</span> решением будет просто избегать наследования везде. Или по крайней мере там, где вы печетесь об оптимизации работы с кэшем. Но вообще культура прораммирования медленно движется в сторону от широкого использования наследования.

    <aside name="type">

    Одним из способов заменить гибкость полиморфизма без наследования  является паттерн <a href="type-object.html" class="pattern">Type Object</a>.

    </aside>

    * *Это безопасно и просто.* Вы всегда знаете с каким классом имеете дело, и все объекты имеют предсказуемо одинаковый размер.

    * *Это быстро.* Вызов динамического метода делаем много лишних телодвижений, включая разбор таблицы виртуальных методов. Хотя эта цена зависит от аппаратного обеспечения, тем не менее всегда есть <span name="cpp">*некоторое*</span> проседание по производительности.

    <aside name="cpp">

    Как водится, "всегда" есть не всегда. Чаще всего, С++ компилятору потребуется затраты на вызов виртуального метода. Но в *некоторых* случаях, компилятор сможет "развиртуализировать" вызов и превратить его в статический, если он будет точно знать, с каким типом он имеет дело. Часто девиртуализация встречается в JIT компиляторах, таких как Java и JavaScript.

    </aside>

    * *Это не так гибко.* Конечно, главная причина использования динамики в том, что легко менять поведение объектов. Если вам нужно, чтобы разные объекты в вашей игре рисовались по-разному, или у них были специфическое движение или атака, то виртуальные методы честно позволят вам реализовать это.  Можно заменить это на какой-нибудь, не виртуальный, метод, внутри которого будет огромный `switch`, но это будет макаронный монстр.

 *  **Отдельные массивы для каждого типа:**

    Полиморфизм нам нужен, чтобы регулировать поведение объекта, чей тип мы не знаем. Другими словами, у нас есть набор разных объектов, которые должны что-то делать, когда мы этого потребуем.

    Но все приводит к вопросу - а откуда вообще взялся этот набор? Почему бы просто не разделить его на несколько однородных коллекций, по одной на каждый тип?

    * *Объекты будут плотно расположены.* Поскольку элементы массива имеют одинаковый тип, там не нужно использовать промежутки для выравнивания или другие странности.

    * *Можно будет вызывать методы статически.* Так как тип объектов известен, то полиморфизм теряет смысл. Можно использовать обычные статические вызовы.

    * *Придется поддерживать несколько коллекций.* Если типов много, то сложности при работе с несколькими массивами могут перевесить плюсы.

    * *Нужно будет знать о каждом типе*. Вам понадобиться *полная* информация о типах, с которыми вы работаете. Полиморфизм отличается тем, что там вам нужно только описание интерфейса -- это достаточно для работы. А описание конкретных типов, которые его реализуют, при этом не требуется.

 *  **Коллекция указателей:**

    Если вы не очень волнуетесь о работе с кэшем, то это естественное решение. Просто заведите себе массив указателей на базовый класс или интерфейс. Весь полиморфизм будет к вашим услугам, и волноваться о размере объектов тоже не понадобится.

    * *Это гибко.* Код, который работает с коллекцией, сможет работать с любыми типами. Достаточно только реализовать требуемый интерфейс. Это легко расширяемое решение.

    * *Кэш не дружит с такими вещами.* Вообще, весь наш разговор начался с темы, что кэш плохо работает с указателями. Но если производительность не критична, то не стоит волноваться раньше времени.

### Как описать игровой объект?

Если вы используете паттерн <a href="component.html" class="pattern">Component</a>,  то у вас будет массивы компонентов, из которых складываются игровые объекты. Игровой цикл будет пробегать прямо по ним, так что сам игровой объект, в принципе, не нужен. Но он может использоваться в некоторых местах. Там, где вы хотите иметь дело с принципиально единой структурой.

Как тогда его представить? Как ему следить за своими компонентами?

 * **Если объект содержит указатели на компоненты:**

    Это то, как что мы взяли в качестве первого примера. Кошерный вариант ООП решения. У вас есть класс `GameEntity`, и в нем есть указатели на компоненты, которыми он владеет. Поскольку это просто указатели, легко понять как и где расположить сами компоненты.

    * *Можно хранить компоненты в линейных массивах.* Поскольку объекту все равно, где физически будут находиться его компоненты, вы можете положить их в массив, весьма удобный для итераций.

    * *Получая объект, вы легко получите его компоненты.* Они просто будут лежать в самом объекте как указатели.

    * *Будет тяжело копировать компоненты.* Если компонент включается и выключается, вам может понадобиться передвинуть его в другое место, если вы хотите держать в массиве только рабочие компоненты. Когда вы скопируете компонент, указатель в объекте становиться невалидным. Нужно быть уверенным, что вы в это же время обновите объект, положив в него указатель на новое место.

 *  **Если в объекте лежат ID компонентов:**

    Указатели в объекте тяжело поддерживать в случае, если вы копируете компоненты с места на место. В этом случае можно адресоваться более абстрактным индексом, который может использоваться чтобы *найти* конкретный компонент.

    Как реализовать индекс и поиск по ним -- зависит от вас. Можно хранить уникальное число и потом бегать по массиву в поисках компонента с таким индексом. Можно сделать что-то вроде хэш-таблицы, которая по этому числу даст в ответ индекс в массиве компонентов.

    * *Это сложнее.* Построить систему индексов проще, чем запустить шатл в космос. Но все-таки сложнее, чем простой указатель. Придется придумать как реализовать и отлаживать такую систему. Вдобавок, это потребует некоторое количество дополнительной памяти.

    * *Это медленнее*. Тяжело сделать что-то быстрее, чем разыменование указателя. Добавится дополнительная работа для получения реального компонента по его индексу.

    * *Появится "менеджер компонентов".* Общая идея -- это иметь некий абстрактный индекс, который однозначно указывает на компонент. Каким-то образом надо будет индекс превратить в компонент. Этим, скорее всего, будет заниматься отдельный класс-менеджер, который обернет ваш массив с компонентами.

        В случае простых указателей, если у вас есть объект, вы сразу получаете его компоненты. В случае индексов, при работе вам <span name="singleton">необходимо</span> иметь и объект, и *менеджер компонентов тоже*.

        <aside name="singleton">

        Первый вариант, который приходит в голову: "Да я просто сделаю синглтон, и все -- проблема решена!". Ну, возможно. Все же, лучше сначала перечитать главу про <a href="singleton.html">синглтоны</a>.

        </aside>

 *  **Если игровой объект сам является ID:**

    Это новое веяние, которое используют некоторые движки. Если выбросить всё состояние и поведение из объекта в компоненты, то что остается? Да, в принципе, не очень много. Единственная функция объекта в этом случае -- это связать все компоненты между собой. То есть, он говорит, что вот *этот* AI, вот *эта* физика и вот *эта* рисовалка описывают одну какую-то сущность в игровом мире.

    Это важно, поскольку компоненты взаимодействуют между собой. Отрисовщик должен знать, где находится объект, а это свойство компонента физики. Когда AI захочет передвинуть объект, ему нужна будет физика, чтобы применить силу. Каждый компонент должен иметь способ узнать своего соседа по объекту.

    Тогда умные люди поняли, все что для этого нужно - это наш ID. Вместо того, чтобы хранить объекты в компоненте, пусто компоненты знают про свой объект. Когда AI компонент знает ID объекта, которому он принадлежит, то ему нужно просто найти физику для такого же ID.

    При этом игровой *объект* исчезает полностью, заменяясь на обертку вокруг простого числа-индекса.

    * *Объекты уменьшаются в размере.* Когда вам нужно передать объект, вы отдаете просто число.

    * *Объект ничего не содержит в себе.* Конечно, если вы убираете все из объекта, то он становится пустым. Не надо туда ничего класть -- все, что нужно знать о свойствах объекта, знают его компоненты.

    * *Не нужно следить на временем жизни объекта.* Поскольку объекты стали типом, который можно передать по значению, то нет смысла выделять и освобождать под них память. Объект умрет сам, когда его компоненты будут уничтожены.

    * *Поиск компонента по объекту может оказаться дорогим.* Это та же проблема, что и в прыдущем варианте. Чтоб найти соседний компонент, придется использовать поиск по индексу. Это может стоить каких-то ресурсов.

        Но здесь потери производительности *станут* критическими. Компоненты часто взаимодействуют между собой во врему игры, поэтому искать придется часто. Как решение, можно в качестве ID использовать индекс массива.

        Если каждый объект имеет одинаковый набор компонент, то массивы с компонентами будут наполняться параллельно. Например, если взять третий компонент в массиве AI и третий компонент в массиве с физикой -- они будут описывать один и тот же объект.

        Это выливается в требование *параллельности* массивов. Это не просто, если появится мысль сделать сортировку или упаковку массивов по какому-то критерию. Например, будут объекты с включенной физикой и остальные, с выключенной. Невозможно будет содержать несколько массивов, отсортированных по разным критериям.

## Что ещё почитать

* Большая часть этой главы крутиться вокруг паттерна <a href="component.html" class="pattern">Component</a>. Компоненты -- это определенно наиболее используемая цель для оптимизации работы с кэшем. На самом деле, используя подход с компонентами, можно облегчить себе задачу. Объекты обновляют одно состояние за другим, поэтому легкие, изолированные компоненты будут очень хорошо ложиться в кэш.

    Это не значит, что *только* при работе с компонентами можно заняться компактностью данных! Каждый раз, когда множество данных начинают обрабатываться в критически важных местах, имеет смысл подумать об улучшении работы с кэшем.

* Презентация Тони Альбрехта <a href="http://research.scee.net/files/presentations/gcapaustralia09/Pitfalls_of_Object_Oriented_Programming_GCAP_09.pdf" class="pdf">"Pitfalls of Object-Oriented Programming"</a> чаще других используется как входная точка в идею о компактности данных. Она открыла глаза многим людям (включая меня!) и заставила понять как важно это для производительности.

* Примерно в это же время, Ноэль Лопис написал [интересный пост](http://gamesfromwithin.com/data-oriented-design) на ту же тему.

* Данный подход широко использует премущества непрерывных массивов однородных данных. Вполне вероятно, что понадобиться добавлять и удалять из него объекты. Глава <a href="object-pool.html" class="pattern">Object Pool</a> рассказывает как раз об этом.

* [Artemis](http://gamadu.com/artemis/) стал первым широко известным игровым движком, который использует ID в качестве игрового объекта.
